{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENABLE_GRIDSEARCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Applied Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first obtain the data and build the TF-IDF document matrix, making sure we exclude english typical stopwords (`the`, `of`, `for`, ...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='all')\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_dm = vectorizer.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dm.shape # shape=(num_docs, num_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we **randomly** split the data in the following way:\n",
    "\n",
    " - 10% for validation\n",
    " - 10% for testing\n",
    " - 80% for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(data.data)\n",
    "t_N = int(0.1 * N)\n",
    "\n",
    "indices = np.random.choice(range(len(data.data)),\n",
    "                           size=2*t_N,\n",
    "                           replace=False)\n",
    "\n",
    "test_ids, valid_ids = indices[:t_N], indices[t_N:]\n",
    "train_ids = np.setdiff1d(np.arange(N), indices, assume_unique=True)\n",
    "\n",
    "assert len(train_ids) + len(test_ids) + len(valid_ids) == N\n",
    "\n",
    "x_train, y_train = tfidf_dm[train_ids], data.target[train_ids]\n",
    "x_val,   y_val   = tfidf_dm[valid_ids], data.target[valid_ids]\n",
    "x_test,  y_test  = tfidf_dm[test_ids],  data.target[test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search is performed in a two dimensional space: one dimension for the number of estimators and one for the maximal depth of the trees. We stored our result in a file to avoid lengthy computations at each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ENABLE_GRIDSEARCH:\n",
    "    # grid search n_estimators and max_depth \n",
    "    validate = lambda n, d: RandomForestClassifier(n_estimators=n, max_depth=d).fit(x_train, y_train)\\\n",
    "                                                                               .score(x_val, y_val)\n",
    "    accuracies = []\n",
    "    for n in range(40, 60):\n",
    "        # run once with no max to get upper bound\n",
    "        for depth in range(75, 90):\n",
    "            score = validate(n, depth)\n",
    "            accuracies.append((n, depth, score))\n",
    "    \n",
    "    with open('grid_search.json', 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "else:\n",
    "    with open('grid_search.json', 'r') as f:\n",
    "        accuracies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies = sorted(accuracies, key=lambda t: t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_, _, accs = zip(*accuracies)\n",
    "ax.plot(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters and the associated score are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have good parameters, we can train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, d, _ = accuracies[-1]\n",
    "rfc = RandomForestClassifier(n_estimators=n, max_depth=d)\n",
    "rfc.fit(x_train, y_train)\n",
    "predictions = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = np.sort(np.unique(data.target))\n",
    "confusion_mat = confusion_matrix(y_true=y_test, y_pred=predictions, labels=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is quite a large matrix, a regular table would hard to display and read at once. Therefore we decided to visualize the confusion matrix as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(confusion_mat,\n",
    "            xticklabels=data.target_names,\n",
    "            yticklabels=data.target_names,\n",
    "            annot=True,\n",
    "            cmap='YlGnBu',\n",
    "            annot_kws={'size': 10},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_ylabel('Predicted class').set_size(20)\n",
    "ax.set_xlabel('Actual class').set_size(20)\n",
    "\n",
    "for tick in [*ax.get_xticklabels(), *ax.get_yticklabels()]:\n",
    "    tick.set_size(15)\n",
    "\n",
    "ax.set_title('Confusion matrix').set_size(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_importance = zip(range(len(rfc.feature_importances_)), rfc.feature_importances_)\n",
    "indices, importances = zip(*sorted(idx_to_importance, key=lambda t: t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "ax1.plot(importances)\n",
    "ax1.set_title('Importances of words, regular axes')\n",
    "ax2.semilogy(importances)\n",
    "ax2.set_title('Importances of words, semilogarithmic axes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we observe that a few features have very high importance. Knowing that each feature is a term, let's see what words are the most important in the classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = {idx: word for word, idx in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 30\n",
    "words = [vocabulary[idx] for idx in indices[-N:]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "ax.barh(range(N), importances[-N:], tick_label=words)\n",
    "\n",
    "ax.set_title(str(N) + ' Most important words for classification').set_size(20)\n",
    "\n",
    "for tick in [*ax.get_xticklabels(), *ax.get_yticklabels()]:\n",
    "    tick.set_size(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
