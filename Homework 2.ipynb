{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping  `topuniversities.com`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'https://www.topuniversities.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = r.get(URL + '/sites/default/files/qs-rankings-data/357051.txt').json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to filter by rank and extract the above properties. Some ranks are of the form: `X-Y` to indicate a range and some start with a `=` to indicate that two universities reached the same rank. As these formats complicate parsing, we first want to check whether the universities we interested in (the top 200) have their rank expressed in one of the two formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dash = set()\n",
    "equals = set()\n",
    "for uni in data:\n",
    "    rank = uni['rank_display']\n",
    "    if '-' in rank:\n",
    "        dash.add(rank)\n",
    "    if '=' in rank:\n",
    "        equals.add(int(rank.lstrip('=')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the intervals is relevant for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(map(lambda v: v < 201, equals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the values starting with `=` are interesting for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ('title',\n",
    "          'country',\n",
    "          'region',\n",
    "          'url'\n",
    "         )\n",
    "\n",
    "# Obtained by inspecting html source\n",
    "to_scrape = ('total student',\n",
    "             'total inter',\n",
    "             'total faculty',\n",
    "             'inter faculty'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "\n",
    "# As explained above, we are not interested in ranks with '-'\n",
    "for uni in filter(lambda u: '-' not in u['rank_display'], data):\n",
    "    # parse rank\n",
    "    rank = uni['rank_display']\n",
    "    rank = np.int8(rank.lstrip('='))\n",
    "    \n",
    "    # Only keep universities in top 200\n",
    "    if rank < 201:\n",
    "        # Retain important fields from ranking table\n",
    "        clean_uni = {variable: uni[variable] for variable in fields}\n",
    "        clean_uni['rank'] = rank\n",
    "        \n",
    "        cleaned.append(clean_uni)\n",
    "        \n",
    "        # Retrieve data from university page\n",
    "        req = r.get(URL + uni['url'])\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        for field in to_scrape:\n",
    "            div = soup.find('div', class_=field)\n",
    "            if div:\n",
    "                clean_uni[field] = np.int32(div.find('div', class_='number')\\\n",
    "                                               .text.strip().replace(',', ''))\n",
    "            else:\n",
    "                print('Could not find', field, 'for', uni['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work without having to pull everything down.\n",
    "with open('bcp.pickle', 'wb') as out:\n",
    "    pickle.dump(cleaned, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bcp.pickle', 'rb') as data_source:\n",
    "    cleaned = pickle.load(data_source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
